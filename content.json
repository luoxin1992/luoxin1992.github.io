{"meta":{"title":"LuoXin's World","subtitle":"有梦为马 随处可栖","description":null,"author":"LuoXin","url":"http://www.lx1992.com.cn"},"pages":[{"title":"关于","date":"2017-01-26T18:12:09.912Z","updated":"2017-01-26T18:12:09.912Z","comments":false,"path":"about/index.html","permalink":"http://www.lx1992.com.cn/about/index.html","excerpt":"","text":"About Me 本名骆欣，貌似有人叫我欣儿:fearful:，90后射手座Boy，目前在厦门大学读研 Not a GIRL! Oops! 论兴趣爱好，怎么说好呢？「倾向于社交成分弱的活动」，平常除了敲代码，可能也就听听歌看看剧了 不就是死宅么 从小学一年级暑假（2000年7月）开始接触「电脑」，但过去那么多年，从没想过未来会以怎样的形式同「计算机」打交道，直到大学选择了「计算机科学与技术」这么个专业 尽管大学时的方向是「嵌入式开发」，没少跟硬件打交道，但从大二开始自学Java，近段时间正在接触以SpringBoot为代表的微服务，未来想要从事后端相关的工作 About Blog曾经的旧博客位于CSDN，近年来因「学业关系」已无暇关顾 听着就好假嘛 新博客基于GitHub Pages + Hexo构建（更新日志），单纯从技术上看些许比较平庸，但毕竟我个人更倾向将这个博客用于个人技术的积累和看法的堆砌 另外纪念下新博客初版正式上线的那天，正好是丙申年的除夕 啥？到底哪天？戳这里学着点？神马？链接打不开？(⊙o⊙)…好吧，那天是2017.01.27 What’s More似乎还少了点什么，Let me see see…噢～博主至今汪一只啊:sob:"},{"title":"分类","date":"2017-01-26T14:08:05.823Z","updated":"2017-01-26T14:08:05.803Z","comments":false,"path":"categories/index.html","permalink":"http://www.lx1992.com.cn/categories/index.html","excerpt":"","text":""},{"title":"更新日志","date":"2017-01-26T17:12:59.403Z","updated":"2017-01-26T17:12:59.403Z","comments":false,"path":"changelog/index.html","permalink":"http://www.lx1992.com.cn/changelog/index.html","excerpt":"","text":"更新日志[1.0.2] - 2017-01-27 告别多说，拥抱Disqus 博客正式上线，祝大家新年快乐、身体健康、阖家幸福 [1.0.1] - 2017-01-26 修复BUG若干 [1.0.0] - 2017-01-25 初始版本 Change Log[1.0.2] - 2017-01-27 Change the comment module from DuoShuo to Disqus Publish online &amp; Happy Chinese new year [1.0.1] - 2017-01-26 Fix some bugs [1.0.0] - 2017-01-25 Init release"},{"title":"留言","date":"2017-01-26T16:23:19.550Z","updated":"2017-01-26T16:23:19.550Z","comments":true,"path":"guestbook/index.html","permalink":"http://www.lx1992.com.cn/guestbook/index.html","excerpt":"","text":"Hi~这里是留言板 任何吐槽 我都会认真对待哒"},{"title":"简历","date":"2017-01-26T14:07:15.278Z","updated":"2017-01-26T14:07:15.266Z","comments":false,"path":"resume/index.html","permalink":"http://www.lx1992.com.cn/resume/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-01-26T14:08:27.347Z","updated":"2017-01-26T14:08:27.343Z","comments":false,"path":"tags/index.html","permalink":"http://www.lx1992.com.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Java8学习之默认方法","slug":"java8-default-methods","date":"2017-01-29T16:19:56.000Z","updated":"2017-01-29T16:43:52.479Z","comments":true,"path":"2017/01/30/java8-default-methods/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/30/java8-default-methods/","excerpt":"这部分是关于的Java8在接口中定义默认方法和静态方法的。实话说，我一时没看出来这个和Lambda表达式有什么关系，也不知道为什么书上会安排在同一章，我还是拆来来吧。","text":"这部分是关于的Java8在接口中定义默认方法和静态方法的。实话说，我一时没看出来这个和Lambda表达式有什么关系，也不知道为什么书上会安排在同一章，我还是拆来来吧。 默认方法同样在Java8以前，接口当中是不会存在任何方法实现的，在某种程度上可以看做纯抽象的的方法。 这就有一个问题，想象有一个接口I，经过若干次迭代，它已经有了A、B、C、D……N个实现类，突然有一天，接口I中不得不新增一个方法，然后它的N个实现类要一一实现这个新的方法吗？可不可以让接口中这个新的方法提供一个默认实现呢？ 恐怕我们很容易联想到早些年AWT中的事件模型，例如窗口事件java.awt.event.WindowListener，它有7个方法未实现，而很可能我们只需要点击关闭窗口时弹出一个确认对话框一个功能……于是就有了java.awt.event.WindowAdapter这么个东西，把每个方法都做了一个空的实现。这样做当然不是不可以，但利用Java8的默认方法要简单不少，用default关键字声明默认方法即可，至少不用定义Adapter类了。12345public interface Lived &#123; default String getDescription() &#123; return &quot;有生命的&quot;; &#125;&#125; 不过新的问题又出现了，Java是允许接口多继承的，万一接口A、B都对某个共享方法X提供了默认实现，偏偏接口C又同时继承了接口A、B怎么办？是不是突然有种当年学C++时解决菱形继承的既视感？莫方，Java8对这种问题的解决办法简单粗暴——开发人员自己决定！也就是说，你必须写代码来决定，究竟是自己再重写一次方法X，还是从A、B的实现中选一个。123456789101112131415public interface Named &#123; default String getDescription() &#123; return &quot;有名字的&quot;; &#125;&#125;public class Human implements Lived, Named &#123; //必须重写冲突的getDescription方法 @Override public String getDescription() &#123; return &quot;人类&quot;; //或可以指定某个父接口的默认实现 //return Lived.super.getDescription(); &#125;&#125; 再换一种情况，假设类C继承了类B又实现了接口A，偏偏接口A对方法X提供了默认实现，类B覆盖了这个实现，在C不重写方法X的情况下，生效的将会是类B中的实现，接口A中的默认实现会被忽略，这称为“类优先”原则。 这就有问题了，而且我个人感觉不是很容易被察觉到：接口也是一种特殊的类，它也是继承Object类的，根据类优先原则，我们就永远不可能为Object类中的方法定义默认实现。 静态方法不知道你有没有被诸如Collection/Collections这样长得贼像的“兄弟”坑过呢？反正我是有，有时候着急了，或者敲快了，还对着错误一头雾水的。其实，这两家伙，前者是接口，后者是类，而且后者为前者提供一些工具方法或者工厂方法。 Java8开始，不仅允许在接口中添加默认方法，还允许添加静态方法了！不知道可不可以认为像Collections这样的类没有太大用处了呢？ 允许这么做是有原因的。即使是默认方法，也需要通过Lambda表达式实例化函数式接口，或者某个实现了这个接口的类的实例才可以访问到，这让静态工厂方法们情何以堪啊？当然下面这个例子有点随意了=.=12345public interface Lived &#123; static boolean instanceOf(Object obj) &#123; return obj instanceof Lived; &#125;&#125;","categories":[{"name":"Java8","slug":"java8","permalink":"http://www.lx1992.com.cn/categories/java8/"}],"tags":[]},{"title":"Java8学习之Lambda表达式","slug":"java8-lambda-expression","date":"2017-01-29T11:23:04.000Z","updated":"2017-01-29T16:43:52.463Z","comments":true,"path":"2017/01/29/java8-lambda-expression/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/29/java8-lambda-expression/","excerpt":"Java8，准确地说应该是JavaSE 8，发布挺长时间了（废话！Java9今年上半年都要出了！），但除了实习那会听同事做了场分享，自己一直没有系统地学习一下。这些天整了本《写给大忙人看的JavaSE 8》，抽点时间读一读，这个系列的博客当是读书笔记了。这第一部分是lambda表达式。","text":"Java8，准确地说应该是JavaSE 8，发布挺长时间了（废话！Java9今年上半年都要出了！），但除了实习那会听同事做了场分享，自己一直没有系统地学习一下。这些天整了本《写给大忙人看的JavaSE 8》，抽点时间读一读，这个系列的博客当是读书笔记了。这第一部分是lambda表达式。 何为lambda表达式lambda表达式是一段可以传递的代码。 过去在多线程、回调等情境（大多是内部类？）下，我们都会把一段代码传递给其他调用者，而这段代码稍后才会被调用。而纯面向对象的Java是不支持传递代码块的，但在Java8中，可以。 第一个lambda表达式，包括两部分——一是代码块本身，二是传递给代码块的参数，注意lambda的返回类型永远是推导来的，不需要显式指定。12// 格式：参数+箭头+表达式(int a, int b) -&gt; foo.bar(a, b); 但lambda的格式也不是说就这么死板，有几种特殊情况：如果代码块不是一个表达式（多行代码、处理异常等），那么就用大括号包裹起来；如果没有参数，那么将小括号置空；如果参数的类型是可以推导的，那么参数类型可以省略；如果有且只有一个可以被推导的参数，那么甚至可以省略小括号。 lambda表达式能做什么lambda表达式有且只能用于函数式接口转换 对只包含一个抽象方法的接口，我们可以用lambda表达式来创建该接口的实例，这种接口也被称作函数是接口。而所谓“一个抽象方法”，则是因为Java8允许在接口中定义非抽象方法。 以java.util.Comparator接口为例123456789101112131415@FunctionalInterfacepublic interface Comparator&lt;T&gt; &#123; //抽象方法 int compare(T var1, T var2); //Object类中有实现，不是抽象方法 boolean equals(Object var1); //有默认实现，不是抽象方法 default Comparator&lt;T&gt; reversed() &#123; return Collections.reverseOrder(this); &#125; //以下省略&#125; 符合上面对函数式接口的定义，因此Comparator是函数式接口，可以通过lambda表达式实例化1Comparator comparator = (a, b) -&gt; foo.bar(a, b); 至于注解@FunctionalInterface，意识可以让编译器帮着检查这个接口符不符合函数式接口的定义，二是生成JavaDoc时对这个接口有一个标记，因此推荐使用。 方法引用对于类似这样的lambda表达式，我们有更方便的写法123//下面两者是等价的(x) -&gt; foo.bar(x)foo::bar 实际上就是将foo这个对象中的boo方法，整个传递给某个函数式接口。方法引用又分成三类 对象::实例方法 类::静态方法 类::实例方法 前两个没有什么特殊之处，注意对象可以是自己或者自己的父类（即this或super），但最后一个，类如何调用实例方法呢？实践后会发现，这种情况下总要求函数式接口中那个抽象方法的参数要比引用的方法的参数多一个，而且这多出来的参数就是类的实例。 更进一步地，我们还可以引用类的构造方法，不过方法名不是我们在反射时见到的，就是简单明了的new了～再特殊一点，如果引用的是数组的构造方法，则需要隐含这一个参数，即数组长度1234567//引用类的实例方法，下面两者也是等价的String::equals(x, y) -&gt; x.equals(y)//引用构造方法String::newint[]::new 捕获在Java8以前，这样的代码会产生编译错误：要求将count声明为final类型，因为我们在一个内部类中引用了外部类的局部变量count，很可能当内部类要用到count时，外部类已经不存在了1234567891011public void runnableWithoutLambda(int count) &#123; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; count; i++) &#123; System.out.println(i); &#125; &#125; &#125;; new Thread(runnable).start();&#125; 但到了Java8，这样做却被“允许”了，当然不可能是无条件的放开，只是不一定要显式地声明final——“等效于final”即可。12345678public void runnableWithLambda(int count) &#123; Runnable runnable = () -&gt; &#123; for (int i = 0; i &lt; count; i++) &#123; System.out.println(i); &#125; &#125;; new Thread(runnable).start();&#125; 事实上，像count这样既不是lambda表达式的参数，也不是定义在lambda表达式的代码块中的变量，被称为“自有变量”，而这个特性被称为“捕获”，含有自有变量的代码块被称为“闭包”。为了实现这个特性，lambda表达式会存储这些变量，既然这些变量等效于final，它们就不允许被修改，即使编译器不报错，尤其在多线程条件下，结果是完全不可预估的。","categories":[{"name":"Java8","slug":"java8","permalink":"http://www.lx1992.com.cn/categories/java8/"}],"tags":[]},{"title":"搭建Redmine「项目管理」服务","slug":"install-redmine-server","date":"2017-01-17T13:44:50.000Z","updated":"2017-01-26T20:01:35.901Z","comments":true,"path":"2017/01/17/install-redmine-server/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/17/install-redmine-server/","excerpt":"Redmine是一款以Ruby on Rails撰写的项目管理和缺陷跟踪工具，和国产的禅道可能有几分类似，但和业内顶尖的Jira应该还是有一定差距的吧？但毕竟人家是开源免费的，相应的功能，诸如项目排期，Bug跟踪，Wiki什么的，对我们这种小团队而言基本也够用了。","text":"Redmine是一款以Ruby on Rails撰写的项目管理和缺陷跟踪工具，和国产的禅道可能有几分类似，但和业内顶尖的Jira应该还是有一定差距的吧？但毕竟人家是开源免费的，相应的功能，诸如项目排期，Bug跟踪，Wiki什么的，对我们这种小团队而言基本也够用了。 现在我们来部署Redmine。先扯一句，网上挺多建议用Bitnami来部署的，的确也是，按照官方的教程来步骤真的挺复杂的，不过既然已入坑，就不半途而废了。首先当然是要下载好Redmine，才2M多，厉害啊，下载完后照例解压缩到/opt目录，另外，安装过程中要下载不少依赖，确保你的服务器能访问外网哈～ 检查Ruby和Rails环境我们即将部署的是最新的Redmine 3.3，这个版本要求Ruby 1.9.3+、Rails 4.2。绝大部分Linux发行版都是预装了Ruby的，可用这两个命令检查服务器上的Ruby和Rails版本，在我们的环境中，两者的版本分别是2.3.1和4.2.7.1，符合Redmine要求。1234# 查看Ruby版本ruby -v# 查看Rails版本rails -v 配置数据库Redmine同样提供了对多种数据库的支持，我们还是选用MySQL。 MySQL侧，自然还是建立一个名为redmine的数据库和用户并授权了，这一步已经重复太多次了。 Redmine侧呢，将./config目录下的database.yml.example文件重命名为database.yml，打开它可以看到这个文件是按着环境分级的，目前我们只需要production环境12345678production: adapter: mysql2 database: redmine host: 127.0.0.1 port: 3306 username: redmine password: &quot;password&quot; encoding: utf8 注意adapter字段是mysql2而不是mysql，据说前者性能高于后者，相关的依赖下一步中我们会安装；port字段默认是没有的，但当你改变了数据库服务器默认的3306端口时就需要加上了；password字段本身的引号最好不要误删。 关于gem这一段其实是写到后面又回过头来补充的。 后文中会多次出现一个叫做gem的东西。gem是以标准格式封装好的ruby程序或库，可以和java的jar做类比；但如果是在命令行中执行gem，其实是调用ruby的包管理器rubygem来管理gem包的行为，可以和nodejs的npm做类比。 在国内，由于某些原因，下载gem包的速度就两个字：呵呵，除了FQ，或者不停地retry，更直接的方法应当是更换国内的gem源。网上大部分资料都建议用淘宝源，但淘宝已经停止对这个源的维护了，后续的维护交由ruby-china进行，所以我们应该更换成ruby-china的源。对gem源的操作使用gem sources命令12345678# 添加ruby-china源gem sources -a https://gems.ruby-china.org/# 移除官方源gem sources -r https://rubygems.org/# 列出当前使用的源gem sources -l# 更新源的缓存gem sources -u 安装依赖Redmine的基本安装过程需要不少依赖，某些依赖又有别的依赖[汗……]，但总的来看，初期安装还不算多，就3个，mysql2、rmagick和rbpdf-font。 首先安装mysql212adb install libmysqlclient-devgem insatll mysql2 一开始我直接执行了第2步，好在mysql2也是蛮贴心的，提示我需要先执行第1步[赞]，安装前置依赖libmysqlclient-dev。 然后是安装RMagick，因为redmine处理一些图片时用到了一个叫做ImageMagick的库，而RMagick作为Ruby和ImageMagick的中间接口，自然也是必不可少的。 但这个的安装就没有mysql2那么幸运了，报错就提示我“可能缺少某些依赖”，可到底缺了啥，谁也不知道，幸好官方文档中说了它还依赖于libmagickwand-dev（咳咳，这个依赖又依赖好多组件哇……）12apt install libmagickwand-devgem install rmagick 最后剩下rbpdf-font了，这个倒没影响我的安装，给我整了个在配置的时候报错[无语]，看在它没啥太复杂依赖的份上，原谅它吧1gem install rbpdf-font 安装redmineredmine使用gem bundler来管理自身的gem依赖，所以首先要安装bundler，然后方可使用bundler安装redmine所需的其他依赖12gem install bundlerbundle install --without development test 注意哦，执行第2步的时候会去读取redmine目录下的Gemfile文件，所以要在redmine目录下执行～然后就静静看着bundler刷刷刷又下载了一堆依赖好了…… 安装后的几个步骤我直接罗列出来了，每一步是干什么的也都给了注释123456# 生成一个随机密钥供session存储使用bundle exec rake generate_secret_token# 创建数据库表结构RAILS_ENV=production bundle exec rake db:migrate# 加载初始数据RAILS_ENV=production REDMINE_LANG=zh bundle exec rake redmine:load_default_data 这里我报了2个错 warning: duplicated key at line 466 ignored: “inodot”LoadError: cannot load such file – rbpdf-font 第1个错误解决的办法是打开报错的这个文件（expanded.rb），按照提示，465行和466行重复了，不知道是个bug还是咋回事，注释掉其中一行就好了； 而第2个错一开始我还挺纠结了，也才有了安装依赖那一小节里边安装rbpdf-font的过程。其实，对于这种扩展依赖，还应该新建一个Gemfile.local文件，在里边加上对rbpdf-font的依赖12# 添加到Gemfile.local中gem “rbpdf-font”, “~&gt;1.19.0” 其他几个配置至此redmine基本上已经安装完成了，确实也没那么简单，但还有几个可选的配置可以看一下。打开./config/configuration.yml（由configuration.yml.example重命名而来，和database.yml一样），里面有3个配置 邮件通知 版本控制 附件目录 其中，邮件通知，根据smtp服务不同，配置文件中已经提供了数种示例，肯定有适合的一种；版本控制，主要是配置同redmine整合的版本控制程序的路径等，默认自动检测一般不会有什么问题；附件目录相对比较重要，因为用户上传的东西什么的都在这里，应当要移动到安全性高一点、空间大一点的目录。 在configuration.yml中没有关于日志的配置，查阅官方文档可知，这个配置是可选的，应当配置在additional_environment.rb中，格式形如123# 构造Logger的3个参数分别是日志文件名、最多保留文件个数、单个文件最大大小(字节)config.logger = Logger.new(&apos;/path/to/logfile.log&apos;, 2, 1000000)config.logger.level = Logger::INFO 最后还有一个名为setting.yml的配置文件，我们无需直接修改它，其中的配置项都可以在redmine运行起来以后，以管理员身份登录去修改。 运行redmine万事俱备只欠东风1bundle exec rails server webrick -e production -b 0.0.0.0 -p 8080 这个命令是用webrick作为http服务器来运行redmine，-e参数指定环境（我们也只有production环境），-b参数指定绑定的ip地址，-p参数指定绑定的端口号。redmine启动后即可通过浏览器访问，初始的用户名密码都是admin。 但是！webrick只适合测试环境使用，据说它有性能问题，网上更多的建议使用thin、puma、mongrel等代替。本着哪个简单用哪个，试试thin吧。 首先自然是安装thin1gem install thin 和rbpdf-font相似，在Gemfile.local中再加入一行1gem &apos;thin&apos; 然后重新运行就可以了1bundle install --without development test 使用thin作为http服务器后，redmine的启动方式有所改变，-e和-p的含义没变，-a指定绑定的且默认就是0.0.0.0，-d在后台运行1thin start -e production -a 0.0.0.0 -p 3000 -d 一般地，还需要将redmine配置成service。","categories":[{"name":"Redmine","slug":"redmine","permalink":"http://www.lx1992.com.cn/categories/redmine/"}],"tags":[]},{"title":"搭建SonarQube「代码质量管理」服务","slug":"install-sonarqube-server","date":"2017-01-17T06:19:42.000Z","updated":"2017-01-26T20:00:38.899Z","comments":true,"path":"2017/01/17/install-sonarqube-server/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/17/install-sonarqube-server/","excerpt":"sonarqube是一个代码质量管理工具，同样是开源的，说白了其实它做的事也是“代码静态分析”，和安装在IDE中的findbugs、checkstyle等插件有几分类似。官方称其支持20+种语言，对java的支持更是不在话下。","text":"sonarqube是一个代码质量管理工具，同样是开源的，说白了其实它做的事也是“代码静态分析”，和安装在IDE中的findbugs、checkstyle等插件有几分类似。官方称其支持20+种语言，对java的支持更是不在话下。 我也是在实习期间第一次接触到这个工具，公司里将它同jenkins这一持续集成工具整合，从而实现每每向git仓库提交代码就自动触发编码质量检查的目的。检查的结果呢，根据问题的类型和严重性，在其web界面上一目了然，老大快瞅瞅哪个程序猿儿欠下了哪些技术债[坏笑]。如果进一步和CI整合，还可以限制诸如代码质量达不到某个级别就不允许进一步操作等，从而确实提高编码质量。 现在我也在自己的云主机上搭建一套sonarqube环境。首先要明确一点，sonarqube从整体上看分成两部分，server和scanner。其中在服务器上安装的为server部分，且server需要连接数据库来存储自身的配置和检查结果等、需要安装插件来实现对不同语言、不同VCS的支持等。至于scanner，那是运行在CI、IDE或者maven等项目管理工具上的，作用就是分析项目。 下载sonarqube在其官方网站上就可以完整下载到，体积看上去不小，再看看最低硬件要求，实话说也蛮高的，我猜测可能和它包含了web服务、cs计算引擎、es全文索引三大件有关吧，下载完毕后解压到/opt目录即可。 配置sonarqube的配置文件位于./conf目录下，包括sonar.properties和wrapper.conf两个，依次打开看看。 sonar.properties这个文件是sonarqube的核心配置文件了，可以/需要配置的东西还是不少的。粗略浏览一下，包括这么几个部分 数据库 Web服务器 SSO鉴权 计算引擎 全文搜索引擎 代理服务器 日志 其他杂项 &amp; 开发者选项 受限于篇幅，本文参考官方教程，简单阐述一些必须的配置。首先自然是数据库老三样——URL、用户名和密码123sonar.jdbc.username=sonarqubesonar.jdbc.password=passwordsonar.jdbc.url=jdbc:mysql://localhost:3306/sonarqube 其次是HTTP服务绑定的网卡和端口12sonar.web.host=0.0.0.0sonar.web.port=9000 最后是官方建议的，对Web服务所在的jvm启用-server参数，据说可以提高性能1sonar.web.javaOpts=-server 哦对了，数据目录和日志目录不必多说，看过我前面几篇博客都应该发现我将所有与业务的这两个目录统一放在/data下了。 至于其他的配置项，由于配置文件里的说明十分详细，有需要的同学可以按着说明调整相关的配置。 wrapper.conf这个文件配置的是Java Service Wrapper，它是啥大伙自行谷歌去。 虽然这个文件标明了，除了JVM路径以外的内容不要修改，但毕竟其中包含了wrapper的日志目录，而且默认的配置是大小不限制、文件数不限制，如果访问量大的话，不可避免地会在程序目录下打出太多的日志，所以还是把这个改一下吧。12345wrapper.logfile=/data/logs/sonarqube/sonar.log# 下面2行默认是注释掉的，相应的特性也被禁用了，根据需要修改wrapper.logfile.maxsize=0wrapper.logfile.maxfiles=0 启动进入./bin目录，可以看到sonarqube支持的各种操作系统中所对应的不同启动程序，以我们的linux-x86_64为例，运行1./sonar.sh start 即可启动sonarqube。通过浏览器访问server的url就可以看到sonarqube的主界面了（当然第一次访问还需要进行一些初始化工作）。 官方的教程中还提到了如何将sonarqube配置成系统服务， 测试注意了，刚才安装和启动的那只是server部分，前面说过，server一般用来查看分析的结果并做相应的处理，我们还需要scanner来进行代码的分析。官方教程中明确了scanner的6种使用方式。因为我们项目是用maven管理的，又暂时没有接入jenkins，所以这里我们直接通过sonarqube的maven插件进行编码质量检查，顺便做个示范。 首先要在项目的pom文件中加上sonarqube的maven插件12345&lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.2&lt;/version&gt;&lt;/plugin&gt; 这个插件只需要配置一个属性，那就是我们前边部署的server的url12345&lt;properties&gt; &lt;sonar.host.url&gt; http://host:port &lt;/sonar.host.url&gt;&lt;/properties&gt; 然后就可以进行编码质量检查了1mvn clean verify sonar:sonar 用不了多长时间结果就会被上传，此时用浏览器打开sonarqube的server端，就可以看到代码分析的结果了，各种不规范、坏味道一目了然。","categories":[{"name":"Sonarqube","slug":"sonarqube","permalink":"http://www.lx1992.com.cn/categories/sonarqube/"}],"tags":[]},{"title":"搭建Redis服务器","slug":"install-redis-server","date":"2017-01-15T06:04:38.000Z","updated":"2017-01-26T20:01:43.785Z","comments":true,"path":"2017/01/15/install-redis-server/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/15/install-redis-server/","excerpt":"Redis，一个开源、支持多种数据结构，亦支持集群和副本且高性能的内存存储。尽管它可被视为内存数据库，但更多地，我们在程序中把它当成缓存使用。缓存的内容也是多种多样，举几个简单的例子，常备访问的数据、维持会话的token，验证码等时效性较强的数据……","text":"Redis，一个开源、支持多种数据结构，亦支持集群和副本且高性能的内存存储。尽管它可被视为内存数据库，但更多地，我们在程序中把它当成缓存使用。缓存的内容也是多种多样，举几个简单的例子，常备访问的数据、维持会话的token，验证码等时效性较强的数据…… 在搭建redis服务器，官方给出的教程是通过源码自行编译和安装。说是说make是个神器，但在ubuntu中，系统的软件源早已为我们准备好了一切，let’s go!1apt install redis-server 一步搞定有木有？嗯，想要挑战一下官方教程的当然也可以，看这里和这里。我自己其实也试验过，没有想象的那么复杂，无非gcc和make报几个错，缺少依赖的头文件什么的，解决起来也挺简单。 前面的一键安装事实上同时安装好了server和client，在终端中运行1redis-cli 就会自动连接localhost:6379上的redis-server，试着执行几个命令(“127.0.0.1:6379&gt;”打头的行是我们的输入，顶格的行是redis的输出)12345678127.0.0.1:6379&gt; pingPONG127.0.0.1:6379&gt; set hello &quot;world&quot;OK127.0.0.1:6379&gt; get hello&quot;world&quot; 这样一来redis其实已经可用了，但还不够，至少我们要修改一下端口号、绑定的网卡、数据和日志文件路径什么的，vim打开/etc/redis/redis.conf，找到下面几行，大概位于50~200行之间，做相应的修改即可1234port 6379bind 127.0.0.1logfile /var/log/redis-server.logdir /var/lib/redis 修改完问题就来了，redis服务停止以后再也启动不了了，因为是systemd启动服务时出错，所以日志打到了/var/log/syslog里边，一开始找了有些时候，看错误日志，说的是 Jan 14 06:08:56 pocket-erp-db redis-server[3118]: Reading the configuration file, at line 108Jan 14 06:08:56 pocket-erp-db redis-server[3118]: &gt;&gt;&gt; ‘logfile /data/logs/redis/redis-server.log’Jan 14 06:08:56 pocket-erp-db redis-server[3118]: Can’t open the log file: Read-only file system 神马？？说日志所在的/data挂载点是只读的？因为/data挂载的是一块云硬盘，实习那会在公司的测试机上也碰到过类似奇怪的问题。但这回先是mount看了一眼，显示是rw的，试着往里写个文件，也没啥异常，这就奇了怪了。 谷歌走起，先是找到了这个，他说是升级以后引入的BUG，重启一下就没事了，但我试了并不管用，后来找到了这个，才是问题根本的原因。 原来redis认定的“Read-only file system”跟mount显示的结果并不是一回事，他有他自己的一套逻辑，这个逻辑实质上位于systemd的配置中，vim打开/etc/systemd/system/redis.service，会看到下面几行1234ReadOnlyDirectories=/ReadWriteDirectories=-/var/lib/redisReadWriteDirectories=-/var/log/redisReadWriteDirectories=-/var/run/redis 原来除了指定的这3个目录，其他目录对于redis来说都是只读的，难怪会报错呢，改就一个字！别忘了改完这个文件要1systemctl daemon-reload 重新加载下systemd。 等下！打住！做这几步操作之前麻烦先把服务停下来，虽然我也不确定是不是就是这个原因，我在服务运行期间做了上面的几个操作，再回过头来想重启服务时，卡在了停止服务那一步，更可怕的是，redis设置了“永不超时”……最后费尽周折好不容易重启了服务，幸好没出啥大篓子。","categories":[{"name":"Redis","slug":"redis","permalink":"http://www.lx1992.com.cn/categories/redis/"}],"tags":[]},{"title":"搭建Disconf「分布式配置管理」服务","slug":"install-disconf-server","date":"2017-01-14T06:33:09.000Z","updated":"2017-01-26T19:13:49.995Z","comments":true,"path":"2017/01/14/install-disconf-server/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/14/install-disconf-server/","excerpt":"disconf是百度开源的一套分布式配置管理平台，详情可以戳这里。 尽管类似的平台不在少数，国内的奇虎、阿里等也均有类似开源实现，但它对于我们后端应用中诸多配置，在使用和管理上之方便，是直到博主进入在某大型O2O公司实习时才深有体会。","text":"disconf是百度开源的一套分布式配置管理平台，详情可以戳这里。 尽管类似的平台不在少数，国内的奇虎、阿里等也均有类似开源实现，但它对于我们后端应用中诸多配置，在使用和管理上之方便，是直到博主进入在某大型O2O公司实习时才深有体会。 试想一下，一个应用，首先肯定有多个环境，至少，线上线下连接的数据库肯定不相同，然后，不论是出于负载均衡，还是可用性方面的考虑，线上业务很可能不是单点的，也就是部署在了多台vm，或者docker中，某天因业务需要，要修改一个配置项…… 先解决前一个问题，纵然通过spring或者maven的profile都可以规避这个问题，更简单一点，写一个脚本，在启动程序时带几个跟当前环境相关的jvm启动参数，欧了；后一个问题，更简单了，配置文件一般不都在resource目录下嘛，改之、打包、部署～可……这样真的好么？ 本文将通过部署disconf来更高效地解决上面的问题。Come on！补充一句，disconf分为disconf-client和disconf-web两部分，client用在我们的业务系统中，web部署在我们的服务器上，本文两部分都会涉及。 相比于其他应用，disconf的部署主要是依赖的的东西不少，而且都是比较重的，什么mysql、redis、zookeeper，好在这一些我们的其他业务系统也要用到，有些呢，甚至早就部署过了。 安装依赖mysql和redis作为最常见的关系数据库、内存数据库（虽然一般用作缓存了），不要说你没有哈，真没有的话，戳这里和这里看我以前的博客。 tomcat和nginx这两个家伙不比上头的数据库们罕见。其实一开始我还奇怪，为什么要同时使用两个web服务器，后来了解到，这是做法叫做“动静分离”，静态web资源依靠nginx，动态依靠tomcat，毕竟nginx在渲染静态资源时效率真的要高出不少。两者的安装和配置请戳这里和这里。 zookeeper最后这个嘛，对分布式、高可用等概念稍微有一点了解的同学应该都听说过，本文暂时不会对它做深入的解释，它的安装，毕竟是可以通过ubuntu的软件源来完成的，方便了不少呢12345# zk需要java环境，一般地，openjdk可以代替oracle jdkapt install openjdk-8-jdk# zookeeperd用于提供zk的启动脚本，从而以服务形式管理zkapt install zookeeper zookeeperd 配置其实这个副标题不是那么恰当，这一步要完成的是下载disconf-web并且修改它的配置文件来适应前边安装好的以来组件。disconf下载有那么一丁点特殊，它没有提供单独的下载地址，既然是github上的一个项目，直接clone吧1git clone https://github.com/knightliao/disconf.git 然后打开./disconf-web/profiles/rd目录，其中有 application.properties jdbc-mysql.properties log4j.properties logback.xml redis-config.properties zoo.properties 共6个文件就是disconf的配置文件，我们需要依次修改。 application.properties首先这个文件是由application-demo.properties重命名而来的，这里边配置的是服务器域名和邮件通知功能。服务器域名，官方文档上说要和后边nginx里的配置保持一致。 jdbc-mysql.properties &amp; redis-config.properties这两个文件看名字猜也猜得到，配置mysql和redis的，我们要修改的主要是如何连接到相应的数据库。另外官方文档要求redis必须配置双实例，就算我们的redis服务单点，也要配置两个。 log4j.properties &amp; logback.xml两个日志框架的配置文件，日志格式个人觉得没有什么修改的必要，但我们所有业务有统一的日志路径，所以日志路径是要修改的。因为没有细读过disconf的源代码，所以不是很清楚它是同时用了log4j和logback还是咋滴，两个文件中总共配置了3处日志，日志文件名分别是disconf-log4j.log、disconf-web.log和monitor.log。 zoo.properties最后这个是zookeeper的配置文件，这个文件原本配置了3台机器组成的zk集群，谁让我们服务都是单点的呢(笑～)，直接改成我们唯一的zk节点的ip和端口。 另外这里有点小问题，此处配置的zk节点信息，client启动时会通过web api去获取和使用，如果我们配置成zk节点的内网ip，那线下可能就访问不到，而如果配置成外网ip，线上使用时所有数据岂不是要到公网上绕一圈？我暂时没有好的办法，配置成了公网ip，再在内网主机的hosts里加一行，强行将公网ip转向内网ip，哪位同学给个更好的解决方案哈～ 打包和部署disconf提供了一个用于打包自身的脚本：.disconf-web/deploy/deploy.sh，运行脚本前要指定好配置文件的所在路径，以及打包的输出路径。12345678910# 指定配置文件文件所在路径ONLINE_CONFIG_PATH=/tmp/disconf/disconf-web/profile/rdexport ONLINE_CONFIG_PATH# 指定打包输出路径WAR_ROOT_PATH=/tmp/disconf/disconf-web/warexport WAR_ROOT_PATH# 执行打包脚本（cd到disconf-web目录下执行）sh deploy/deploy.sh 可能要经过一段时间的等待（毕竟要下载不少jar包），打开刚才指定的目录输出路径，可以看到是一个熟悉的web项目的结构。吐槽一句，既然部署脚本已经帮忙把war包给解压了，那为何不好人做到底，把已经没用的war包顺手删掉呢？还有打包时复制过去的配置文件同样也是多余的呀。 在正式部署之前还有一件事要做——初始化数据库，要用到的sql，disconf也都提供好了，位于./disconf-web/sql目录下，包括4个文件，执行的顺序看其中的readme吧。当然，这都是可以修改了，像什么环境啦，用户啦都可以定制得更符合我们的需要，还有许多测试数据可能也是我们不需要的。 初始化好了数据库就可以开始部署了。前面说过，disconf做了动静分离，因此部署分两个部分。先部署动态部分（tomcat），修改tomcat端口为disconf的后端端口号（这里假定本机的tomcat上就跑这么一个应用～），打开配置目录下的server.xml文件，在节点下添加这么一个虚拟主机，映射到站点根目录上1&lt;Context path=&quot;&quot; docBase=&quot;/opt/disconf&quot; /&gt; 再部署静态部分（nginx），同样假定本机的nginx只被disconf使用，因此直接修改default站点（/etc/nginx/site-available/default文件）123456789server &#123; listen 80 default_server; root /opt/disconf/html; index index.html; server_name _; location / &#123; try_files $uri $uri/ =404; &#125;&#125; 重新启动tomcat和nginx就完成了disconf的部署。注意这里完全将动态资源和静态资源分离了，这是因为我们还有另一台更前置的nginx，根据具体的uri匹配请求的资源应该被反向代理到这里的tomcat还是nginx上，因此如果到这一步要进行测试的话，记得访问动静态资源的端口号是不一样的。","categories":[{"name":"Disconf","slug":"disconf","permalink":"http://www.lx1992.com.cn/categories/disconf/"}],"tags":[]},{"title":"配置ssh端口转发","slug":"ssh-port-forwarding","date":"2017-01-11T08:01:24.000Z","updated":"2017-01-26T19:58:09.723Z","comments":true,"path":"2017/01/11/ssh-port-forwarding/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/11/ssh-port-forwarding/","excerpt":"接触linux的同学不可避免地要常常接触ssh，一般地，我们都可以在本地主机（下称host1）上通过ssh命令直接连接另一台远程主机（下称host2）来执行想要的命令。 但在某些情况下，因为存在防火墙，或者两台主机不在同一个网络，再者其他别的什么原因，可能我们无法直接从host1登录host2。","text":"接触linux的同学不可避免地要常常接触ssh，一般地，我们都可以在本地主机（下称host1）上通过ssh命令直接连接另一台远程主机（下称host2）来执行想要的命令。 但在某些情况下，因为存在防火墙，或者两台主机不在同一个网络，再者其他别的什么原因，可能我们无法直接从host1登录host2。 要解决这个问题，办法也不少，比方说在防火墙上打个洞，至少把host2的主机的ssh端口暴露出来，当然，这一般不是我们所期望的解决方案；更为常见的办法，是再找一台既能够被host1访问，又能够被host2访问的主机（下称host3）用作跳板，从而间接实现host1登录host2。&lt;!–，示意图如下 –&gt; 要实现这个效果，办法又有不止一种，之前也介绍过用iptables实现端口映射，本文则主要讲讲如何用ssh的“端口转发”（Port Forwarding）功能实现类似的效果。 ssh的端口转发分为3种，本地转发、远程转发和动态转发。 本地转发用法1ssh -L [&lt;local host&gt;:]&lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;ssh host&gt; 例如，在host1上执行1ssh -L 7001:&lt;host2&gt;:8001 &lt;host3&gt; 即可建立host1到host3的ssh连接，并在host1上监听7001端口，将到达此端口的数据，通过host3，转发到host2的8001端口上。 注意一点，host1默认只在本地回环的7001端口上监听，所以从host1以外的主机是无法使用这个本地转发的，如果需要别的机器使用，有两种办法：一是带上常被忽略的[:]参数，并且写成0.0.0.0来监听host1所有网卡；二是带上-g参数，顺带着补充几个ssh常见的参数：-f后台运行，-C压缩数据，-N不执行命令。 远程转发用法1ssh -R [&lt;local host&gt;:]&lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;ssh host&gt; 首先要想想为什么会有远程转发的存在。很多时候，我们的host3面临这样一种境地，它可以访问外网，但外网不能访问它，最常见的就是host3位于nat路由之后的情形。这种情况下本地转发就失效了，此时需要host3反过来主动建立到host1的连接，应当在host3上执行1ssh -R 7002:&lt;host2&gt;:8002 &lt;host1&gt; 类比本地转发，这次建立的是host3到host1的ssh连接，并在host3上监听7002端口，将到达此端口的数据，转发到host2的8002端口上。 有点晕？其实本地转发和远程转发两者最显著的差异在于一开始host1和host3建立ssh连接的方向，谁是ssh client，谁是ssh server，其他数据流的方向是一样的。如果这个ssh连接的方向，和端口转发的方向一致，那么就是“本地转发”，否则是“远程转发”。假如host1和host3之间本身就可以互相访问，那这两种转发用哪一种都可以。 动态转发用法1ssh -D [&lt;local host&gt;:]&lt;local port&gt; &lt;ssh host&gt; 最后这个动态转发和前面两者不太一样，无论本地转发还是远程转发，都要指定怎么转发，但有时候这个不是我们一开始就能确定的。其实，在动态转发中，ssh扮演了SOCKS(5)代理的角色，具体实现是SOCKS协议的事了，超出了本文的范畴。如果你在host1上执行了1ssh -D 9001 &lt;host3&gt; 那么host1上的其他应用就可以设置127.0.0.1:9001作为自己的SOCKS(5)代理服务器了。 实现连接维持不知道各位看官发没发现一个问题，上面的所有操作，都是基于事先建立好的一个ssh连接之上的，但连接毕竟是连接啊，谁知道啥时候就断了呢？万一连接断了，岂不是又要我们人工登录上去重新配一次端口转发，这多麻烦！这时就可以请出autossh这货了。它是干啥滴？ autossh is a program to start a copy of ssh and monitor it, restarting it as necessary should it die or stop passing traffic. man一下，说的很清楚，它用来启动一个ssh连接并监视它，一旦它挂了就重启它。具体的原理呢，就是在建立ssh连接的2台主机之间再建立1个用于监视的连接，而这个连接上定期有测试数据传送。 啊，别问我如果这个监视的连接也挂了该怎么办。。。而且理论上，如果建立ssh连接的时候附带着执行一条会定期产生数据传送的命令，应该也可以实现类似的效果吧？ 至于使用，autossh主要就多了一个-M参数，指定2个端口号，分别用于监视数据的发送和接收，如果只指定了其一，另一个自动取给定的这个端口号+1；至于-f参数，我又在这里踩坑了，也是看了帮助文档以后才知道，虽然和ssh里的-f一样都是使命令在后台运行，但给autossh加上-f可能会导致ssh无法输入密码什么的，所以这个参数放在ssh里头好了。 举个栗子，autossh的用法1autossh -M 4444 -gNfL 2222:192.168.1.102:3333 user@192.168.1.103 就可以实现“在后台建立到192.168.1.103的ssh连接，不执行命令但用于将到达本机2222端口的数据转发到192.168.1.102的3333端口，而且它是可被共享的；另外通过4444和4445端口监视这个ssh连接的存活状况，如果发生异常会自动重连”。对了，最好将autossh添加到开机启动里头哦，否则机器一重启，我们的配置又没有了。 参考资料实战 SSH 端口转发SSH的三种端口转发（Port forwarding）SSH反向连接及Autossh","categories":[{"name":"Linux","slug":"linux","permalink":"http://www.lx1992.com.cn/categories/linux/"}],"tags":[]},{"title":"用Postfix实现通过外部SMTP服务转发邮件","slug":"send-mail-using-external-smtp-by-postfix","date":"2017-01-10T08:49:30.000Z","updated":"2017-01-26T19:56:19.468Z","comments":true,"path":"2017/01/10/send-mail-using-external-smtp-by-postfix/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/10/send-mail-using-external-smtp-by-postfix/","excerpt":"项目中许多地方都需要邮件通知功能。以开发工具为例，譬如，Gogs在版本库变化时可以通知团队成员、Redmine在项目（任务）进度变化时也有类似的功能，更进一步地，程序上线后将会配置相应的JVM监控，以便于发生线上故障时（程序抛出非预期的异常等）及时通知开发者处理。","text":"项目中许多地方都需要邮件通知功能。以开发工具为例，譬如，Gogs在版本库变化时可以通知团队成员、Redmine在项目（任务）进度变化时也有类似的功能，更进一步地，程序上线后将会配置相应的JVM监控，以便于发生线上故障时（程序抛出非预期的异常等）及时通知开发者处理。 但是，有几个问题需要留意。首先是如何发送邮件？自己搭建一套完整的邮件服务？真的这样做的话，可以以类似&#109;&#x61;&#105;&#108;&#64;&#x6d;&#x79;&#100;&#111;&#x6d;&#97;&#105;&#110;&#x2e;&#x63;&#111;&#x6d;的名义发送邮件，看上去是逼格满满，可就算不考虑这个操作的复杂性，在这个垃圾邮件泛滥的时代，十有八九这种自己发送的邮件会面临各种限制。再者，更现实一点，这些程序都运行在内网主机上，如何向外部发送邮件呢？ 其实，使用邮件中继转发（relay）服务就可以完全解决上面这些所谓的“问题”。邮件中继转发，简单地说，就是邮件的最终递送仍旧由外部SMTP服务完成，163、QQ、Gmail什么的都可以，他们不是更专业吗？而我们的邮件服务器只是扮演一个代理的作用而已。 肩负邮件中继转发这一使命的，也就是本文的主角——Postfix。想要详细学习了解的同学可以戳这里)。在本例中，我们的程序将要发送的邮件交给Postfix，然后就没有然后了，完全不知道，也不需要知道邮件最后怎么样了。而收到邮件的Postfix，就像我们在邮件客户端（Foxmail、Thunderbird等）里点击“发送”按钮一般，将邮件交由配置好的外部SMTP服务。 下面直接介绍开始配置的过程。 安装Postfix1apt install postfix 安装过程中有3次同用户的交互。 首先是询问你邮件服务器类型，网上大部分资料，选择的都是Internet site，但其实，纯粹用作邮件中继转发，选择Satellite system就可以了。 然后是设置邮件域名，这里Postfix默认填入了主机名，因为不是直接通过我们的主机对外发送邮件，这一步的意义似乎没有网上教程说的那么邪乎，还要配置DNS的MX记录的。 最后是设置Postfix将收到的邮件中继转发给谁，也就是外部SMTP服务器的地址，本例中我们使用阿里云邮，按照它的说明，这里应该填入[smtp.aliyun.com]:465。注意：如果第一步选择了Internet site，那么这一步就不会出现了，可以在安装完成后直接去修改配置文件。 配置main.cfPostfix的主要配置文件为main.cf和master.cf，其中后者一般可以直接保持默认，配置邮件中继转发服务仅需要修改前者，vim打开这个文件，找到其中这几行（没有的话就自己加上），并且修改等号后面的内容123456789101112131415inet_interfaces = allinet_protocols = ipv4mynetworks_style = subnetmynetworks = 127.0.0.0/8, 192.168.207.0/24smtpd_use_tls = norelayhost = [smtp.****.com]:465smtp_sasl_auth_enable = yessmtp_sasl_password_maps = hash:/etc/postfix/sasl_passwdsmtp_sasl_security_options = noanonymoussmtp_use_tls = nosmtp_tls_wrappermode = yessmtp_tls_security_level = encrypt 可能这个地方又和网上的教程不太一致了，但也是博主自己反复踩坑、修改文件后得出的一组能够正常工作的配置。 inet_interfaces：配置Postfix监听的网卡，常见的选项包括all和loopback-only，当然也可以指定具体的IP+端口号，但官方的建议是这个选项直接保持默认，因为还有许多别的途径可以满足类似的需求。 inet_protocols：配置Postfix使用的网络协议，毕竟在我国ipv6只用在教育网，直接把这项配置成ipv4还可以免去诸如::1这样的IP地址出现。 mynetworks：配置Postfix可信任的客户端，本例中采用了CIDR写法，对来源是本机，或者本机所在局域网（192.168.207.0网段）的邮件才予以中转。这个和mynetworks_style是相呼应的，一般设置这个即可。 smtpd_use_tls：这个的缺省值是yes，并且还配置了证书，但估计就是证书的问题，发送邮件时报了一个关于证书的错误。考虑到我们搭建的是close relay且仅在内部使用，对安全性要求没那么高，直接关掉这个选项了事。 relayhost：这个应该在安装的第三步已经配置过了，当时没配的，这里补上吧。 smtp_sasl打头的3个选项：分别用于配置外部smtp服务是否需要授权？授权信息保存在哪？有哪些授权限制？答案是当然需要授权、授权信息保存在/etc/postfix/sasl_passwd中（后面会单独配置）、不允许匿名登录。 smtp_use_tls：这个的缺省值也是yes，按照我所使用的外部smtp服务方的说明，应该是要启用这个选项了，但是一旦启用就提示connection time out，也不像是证书又惹祸了，知道原因的同学可以说一声呀。 smtp_tls打头的2个选项：这最后2个原本我是没有配置的，网上的教程似乎也没提及，但是配置成功、发送邮件时有个警告，建议我加上，那就加上吧…… 配置sasl_passwd前面提到过，关于外部SMTP服务授权相关的信息保存在sasl_passwd中，按照官方的建议，我们创建/etc/postfix/sasl_passwd文件，并在其中填入1$relayhost username:password 注意：这个relayhost和main.cf中的必须一致（所以我给加了个$符），毕竟要建立映射关系的。我在这里踩了两次坑，第一次是两个地方配置不一致，第二次是密码居然输错了……报错前者是“需要认证”，后者是“认证失败”，因此耽搁了一点时间。 然后转换成Postfix需要的hash格式（生成sasl_passwd.db文件）1postmap /etc/postfix/sasl_passwd 注意：我们将邮箱密码明文保存在sasl_passwd中了，出于安全性考虑，建议将这个文件的权限设置成只有root用户可读。 测试一下至此，Postfix的配置就完成了，重启之。嗯，其实Postfix提供了重新载入配置文件的方法，很多时候并不需要重启1postfix reload 莫忘了把我们的程序中的SMTP服务器填写成“Postfix服务器地址:25”，然后发送一封测试邮件。瞅一眼日志，发送成功！12Jan 10 16:32:02 ubuntu-server postfix/smtp[3946]: 9D6E381168: to=&lt;****@163.com&gt;, relay=smtp.****.com[*.*.*.*]:465, delay=0.5, delays=0/0/0.25/0.25, dsn=2.0.0, status=sent (250 Data Ok: queued as freedom)Jan 10 16:32:02 ubuntu-server postfix/qmgr[3942]: 9D6E381168: removed P.S.日志位于/var/log/mail.log中，Postfix设计的原则就是Linux已经有的，绝不重复造轮子，所以…… 参考资料How to Set Up a Mail Relay with Postfix and Mailgun on Ubuntu 16.04 Configure Postfix to use Gmail as a Mail RelayConfigure Postfix to Use Gmail SMTP on UbuntuConfigure Postfix to Send Mail Using an External SMTP Server","categories":[{"name":"Postfix","slug":"postfix","permalink":"http://www.lx1992.com.cn/categories/postfix/"}],"tags":[]},{"title":"搭建Gogs「私有Git版本控制」服务","slug":"install-gogs-server","date":"2017-01-06T06:03:19.000Z","updated":"2017-01-26T19:54:11.892Z","comments":true,"path":"2017/01/06/install-gogs-server/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/06/install-gogs-server/","excerpt":"Gogs(Go Git Service)是一款使用Go语言开发，极易以最简单、最快速和最轻松的方式搭建的自助Git服务。","text":"Gogs(Go Git Service)是一款使用Go语言开发，极易以最简单、最快速和最轻松的方式搭建的自助Git服务。 相比于这个系列下面其他开发工具的安装和配置，gogs还算是比较简单的。另外考虑到建立linux/mysql用户、tar解压缩这一类的简单操作已经重复了太多次，本文就不再重复讲述了。 首先将下载好的安装包解压到/opt目录下，并在mysql中运行scripts子目录下的mysql.sql文件。这步操作实际上就是创建了一个名为gogs、编码为utf8mb4的空数据库，因此也可以自己在mysql中创建。 随后切换回上层目录（/opt/gogs），运行1./gogs web 即可使用 http://ip:3000 访问gogs服务，进行进一步的安装和配置，包括gogs运行环境、数据库、管理员账户等。 到此为止，gogs的安装和配置基本上就完成了，但还是以普通进程方式运行的，我们还应当配置为以服务或守护进程的方式运行，保证gogs服务开机自启动且稳定运行。 这就完了？！我自己都觉得这次写的好水啊……","categories":[{"name":"Gogs","slug":"gogs","permalink":"http://www.lx1992.com.cn/categories/gogs/"}],"tags":[]},{"title":"重置MySQL服务器","slug":"reset-mysql-server","date":"2017-01-03T13:36:15.000Z","updated":"2017-01-26T19:46:44.287Z","comments":true,"path":"2017/01/03/reset-mysql-server/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/03/reset-mysql-server/","excerpt":"也不知道是造了什么虐，昨天搭建好的MySQL服务器今天竟然挂了。。。无奈又写了这篇。这篇文章主要包括两个部分，一是如何重置root密码，二是如何直接重建整个数据库。除非遇到一些比较极端的情况，否则所述的内容可能不会很常用。","text":"也不知道是造了什么虐，昨天搭建好的MySQL服务器今天竟然挂了。。。无奈又写了这篇。这篇文章主要包括两个部分，一是如何重置root密码，二是如何直接重建整个数据库。除非遇到一些比较极端的情况，否则所述的内容可能不会很常用。 1. 重置root密码重置密码的步骤从网络上的资料看五花八门，所以还是参考官方指南更靠谱。 这个教程给出了3种方案，说是分别对应Windows系统、(类)Unix系统，和通用方案。我采用了其中的“通用方案”，总共分为6个步骤。 1.1 停止mysql服务1service mysql stop 1.2 加上参数–skip-grant-tables重启mysql服务这个是需要以安全模式直接启动mysqld守护，因此和大多数情况下用service操作不太一样。如果不愿意这么做，也可以把这个参数直接加进配置文件里123[mysqld]# 加上这么一行，其他配置保持不变skip-grant-tables 教程中还建议一并加上–skip-networking参数。因为在skip-grant-tables模式下，mysql不需要输入密码就可以登录，这是相对不安全的，skip-networking可以阻止通过网络访问mysql。 1.3 直接登录mysql1mysql -uroot 1.4 重置密码因为skip-grant-tables的原因，alter user、set password等操作都会被拒绝，教程里仍然提到了这个办法，可能是兼容性的考虑吧。 此时要修改密码，可以直接修改user表，注意保存密码的字段已经不是老教程里说的password了，而是authentication_string。12345678# 切换数据库use mysql;# 更新密码字段update user set authentication_string = password(&apos;&lt;new_password&gt;&apos;) where user = &apos;root;# 刷新权限flush privileges; 1.5 恢复配置并重启服务就是删除或者注释掉刚加在配置文件里的skip-grant-tables，然后按照正常的方式重新启动mysql服务。 1.6 用新密码登录mysql1mysql -uroot -p 登录成功，但是执行任何操作都提示需要“重置密码”，不过这次就可以使用正常的方式修改密码了。12345# 适合5.7.6及以后版本alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos;&lt;new_password&gt;&apos;# 适合5.7.5及以前版本set password for &apos;root&apos;@&apos;localhost&apos; = password(&apos;&lt;new_password&gt;&apos;); 2. 重建整个数据库需要重建整个数据库的概率应当比重置root密码更低，一般是数据库发生了比较严重的故障或者损坏，且数据都不太重要或者做好了备份的情况下，直接清除掉现有的全部内容，恢复mysql服务到最原始的状态。总共分为4个步骤。 2.1 停止mysql服务1service mysql stop 2.2 删除数据目录（data_dir）下的全部文件123# 视data_dir而定cd /var/lib/mysqlrm -rf * 如果没有做这一步，下一步会提示“数据目录中存在文件，操作失败” 2.3 重建数据库1mysqld --initialize 2.4 重启服务1service mysql start 注意因为数据库已经被重置了，我也不知道新的root密码是什么了，试了下不是空密码，所以还得乖乖参考上一步，重置下密码。","categories":[{"name":"MySQL","slug":"mysql","permalink":"http://www.lx1992.com.cn/categories/mysql/"}],"tags":[]},{"title":"配置ssh免密码登录","slug":"ssh-public-key-login","date":"2017-01-02T11:59:47.000Z","updated":"2017-01-26T19:52:33.904Z","comments":true,"path":"2017/01/02/ssh-public-key-login/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/02/ssh-public-key-login/","excerpt":"绝大多数情况下，我们都是通过ssh登录到云主机的，这个命令就是最最常规的ssh方式登录1ssh username@hostname 但一般地，线上主机多多少少会有一些额外的登录限制（当然，还是出于安全性的考虑）。常见的限制包括，限制从某些主机登录，限制用ssh密钥而不允许用密码登录等，这篇博客说说如何来配置后一种限制。","text":"绝大多数情况下，我们都是通过ssh登录到云主机的，这个命令就是最最常规的ssh方式登录1ssh username@hostname 但一般地，线上主机多多少少会有一些额外的登录限制（当然，还是出于安全性的考虑）。常见的限制包括，限制从某些主机登录，限制用ssh密钥而不允许用密码登录等，这篇博客说说如何来配置后一种限制。 1. 配置ssh免密码登录这一步除了安全性因素外，其实懒也占了挺大一块的，ssh登录在后期是要大量使用的，每次输入密码真的太麻烦，所以在这里配置下ssh免密码登录。 它的原理也很简单，假设要从A机器登录B机器，默认地会要求输入B机器的密码，但如果B机器上有A机器的公钥，就可以跳过这个步骤。所以我们要做的，就是在A机器上生成密钥对，并将其中的公钥提供给B机器。 1.1 在A机器上生成ssh密钥对1ssh-keygen -t rsa 运行后一路回车，即可在~/.ssh目录下生成id_rsa和id_rsa.pub两个文件，其中带.pub后缀的就是公钥，另一个是私钥，千万不能泄露哦！ 1.2 将公钥传输到B机器1scp ~/.ssh/id_rsa.pub username@hostname:~/ 其中的username是B机器的用户名，hostname是B机器的主机名或IP地址，这时还是要输入密码的。 1.3 使B机器信任A机器的公钥1cat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 这里补上后来学到的另一种方案，可以用ssh-copy-id代替scp手动复制文件、cat重定向公钥（即1.2、1.3步）1ssh-copy-id username@hostname 1.4 配置权限这一步网上的说法也是必须的，虽然一开始我没有配置这一步也没有出错，但是仔细想想出于安全性的考虑还是做一下为妙。所要完成的任务就是把B机器的.ssh目录权限设置成700（仅用户本人可以读、写、访问）， authorized_keys文件权限设置成600（仅用户本人可以读、写）。12chmod 700 .sshchmod 600 .ssh/authorized_keys 行了！试一下，在A机器上直接ssh username@hostname不再需要输入密码就直接登录了。 2. 关闭密码登录上一步实现了ssh密钥登录，即快捷又方便，那么自然就可以关闭密码登录了。vim打开/etc/ssh/sshd_config文件，找到并修改下面2行12PubkeyAuthentication yesPasswordAuthentication no 然后重启一下sshd1service sshd restart 搞定！现在再想使用密码登录会告诉你，不行！安全性进一步提高了。","categories":[{"name":"Linux","slug":"linux","permalink":"http://www.lx1992.com.cn/categories/linux/"}],"tags":[]},{"title":"Ubuntu简单用户管理","slug":"user-config-in-ubuntu","date":"2017-01-02T11:41:20.000Z","updated":"2017-01-26T19:50:28.816Z","comments":true,"path":"2017/01/02/user-config-in-ubuntu/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/02/user-config-in-ubuntu/","excerpt":"系统环境现在已经有了。也是出于成本的考虑吧，目前我们的项目会在一台主机上搭建多个服务，以部署开发工具的那台云主机为例，就包括git、maven、sonarqube等。 而linux本身作为一个多用户、多任务的系统，从减少耦合的角度看吧，也应该为每一个应用创建一个用户（话说没有人会希望一个简简单单的操作用的都是root用户吧）。","text":"系统环境现在已经有了。也是出于成本的考虑吧，目前我们的项目会在一台主机上搭建多个服务，以部署开发工具的那台云主机为例，就包括git、maven、sonarqube等。 而linux本身作为一个多用户、多任务的系统，从减少耦合的角度看吧，也应该为每一个应用创建一个用户（话说没有人会希望一个简简单单的操作用的都是root用户吧）。 1. 创建用户在ubuntu系统中创建用户需要这么几个步骤。这里假设我们都能分清用户、用户组等概念了。首先是添加用户组1sudo groupadd &lt;groupname&gt; 这样就添加了一个名为groupname的用户组。而后是添加用户1sudo useradd &lt;username&gt; -g &lt;groupname&gt; -m 这样就添加了一个名为username的用户，参数-g表示把新增加的用户添加到groupname用户组，-m表示为新增加的用户创建家目录。 最后当然要设置一个密码，输入下面这个命令，回车后输入2次username用户的新密码1sudo passwd &lt;username&gt; 上面这种是比较常规的方法，ubuntu系统中还有一个命令可以一次性完成这3个步骤1adduser &lt;username&gt; 不就是把useradd的2个单词反一下嘛～接下来具体的操作这个命令的提示得很完善了。 2. 赋予新用户sudo权利用户也已经添加好了，不过当我们切换到username，准备sudo各种命令时会看到提示1username is not in the sudoers file. This incident will be reported. 网上对此问题的解决方案也是挺多的，什么直接编辑/etc/sudoers，什么visudo，个人觉得更简单的办法是将username一并添加到sudo用户组1sudo gpasswd -a &lt;usrname&gt; sudo 因为/etc/sudoers中有这么一段话12# Allow members of group sudo to execute any command%sudo ALL=(ALL:ALL) ALL 当然用传统的1usermod -aG &lt;groupname&gt; &lt;username&gt; 也是阔以的。","categories":[{"name":"Linux","slug":"linux","permalink":"http://www.lx1992.com.cn/categories/linux/"}],"tags":[]},{"title":"上美团云Ubuntu主机咯","slug":"install-ubuntu-on-mos","date":"2017-01-02T11:15:01.000Z","updated":"2017-01-26T19:26:49.774Z","comments":true,"path":"2017/01/02/install-ubuntu-on-mos/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/02/install-ubuntu-on-mos/","excerpt":"其实我一直挺纠结这标题的，要不要这么高调嘛……况且原本的标题是《美团云Ubuntu主机折腾记》，可仔细想，我折腾啥子了？！明明就是几个配置好不啦。 言归正传，项目中会用到数台云主机，今天终于鼓起勇气下了单。当然出于复杂性的考虑，这些云主机的操作系统没有采用线上更常见的CentOS，转向更为寻常的Ubuntu，当然是没有GUI的Server版。","text":"其实我一直挺纠结这标题的，要不要这么高调嘛……况且原本的标题是《美团云Ubuntu主机折腾记》，可仔细想，我折腾啥子了？！明明就是几个配置好不啦。 言归正传，项目中会用到数台云主机，今天终于鼓起勇气下了单。当然出于复杂性的考虑，这些云主机的操作系统没有采用线上更常见的CentOS，转向更为寻常的Ubuntu，当然是没有GUI的Server版。 云主机创建好以后，观察了一下，美团云这系统模板做的还是不错的，基本上可以立即使用，有一些小的点稍稍处理下也不会耽误太多的时间。 首先是语言环境，系统默认的是en_US.UTF-8，似乎改成中文也没有什么不妥的1dpkg-reconfigure locales 运行后会出现一个向导，第一步是选择需要支持的语言环境，默认只选中了en_US.UTF-8，要把zh_CN.UTF-8也一并勾上；第二步是选择默认的语言环境，同样选择zh_CN.UTF-8。OK，等待配置完成。 默认的语言环境配置成中文后，直接从tty登录会看到大量口口口，其实就是中文乱码了，解决的办法也不是没有，把这段脚本加到bash_profile里即可1234if [ $TERM == &quot;linux&quot; ] &amp;&amp; [ !-e $SSH_TTY ]; then export LANG=&quot;en_US.UTF-8″ export LANGUAGE=&quot;en_US.UTF-8″fi 不过绝大多数情况下我们都是用ssh登录，这一步其实可做可不做了。网上的另一种说法是通过安装zhcon临时解决，这是一个类似ucdos的插件，从理论上说，对性能会在一定程度的影响。 然后还需要配置下时区，这个系统模板默认的时区是美国时间，和北京时间差了13小时，每次看时间都要做下转换也是不爽1dpkg-reconfigure tzdata 在这个向导中选择亚洲（Asia）–&gt;上海（Shanghai），OK，这下时间对上了。 最后一步，更新下系统吧，把Linux包管理的特性利用起来，再说线上主机，基本的安全性还是要保证的12apt updateapt upgrade 相信这两个命令没有同学说不知道了吧[微笑]","categories":[{"name":"Linux","slug":"linux","permalink":"http://www.lx1992.com.cn/categories/linux/"}],"tags":[]},{"title":"Ubuntu设置全局代理","slug":"set-global-proxy-in-ubuntu","date":"2017-01-01T09:23:13.000Z","updated":"2017-01-26T19:49:31.106Z","comments":true,"path":"2017/01/01/set-global-proxy-in-ubuntu/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/01/set-global-proxy-in-ubuntu/","excerpt":"之前有一篇文章用iptables做端口映射，实现了从外网直接ssh连接一台内网云主机，但即便这样，还是存在一些问题，譬如，apt仍旧无法访问外部源。 至于原因哈，猜一个，因为前面配置端口转发的时候只映射了22端口，而更新软件源等，使用的是http的80端口，些许应该再配置下http的80端口、https的433端口…… 一不做二不休，直接在外网主机上用squid架设代理服务器，不就免去这一切乱七八糟的事了吗？架设代理服务器的过程后面会补上（又给自己挖坑呢）。","text":"之前有一篇文章用iptables做端口映射，实现了从外网直接ssh连接一台内网云主机，但即便这样，还是存在一些问题，譬如，apt仍旧无法访问外部源。 至于原因哈，猜一个，因为前面配置端口转发的时候只映射了22端口，而更新软件源等，使用的是http的80端口，些许应该再配置下http的80端口、https的433端口…… 一不做二不休，直接在外网主机上用squid架设代理服务器，不就免去这一切乱七八糟的事了吗？架设代理服务器的过程后面会补上（又给自己挖坑呢）。 配置好代理服务器后，自然要把内网主机的代理配置指向这台外网主机。谷歌了一下，大部分文章提到的3种办法。一是直接执行1export http_proxy=“proxy_username:password@ip:port” （这只针对当前会话有效）；二是把上述内容添加到~/.bashrc中（实现当前用户每次登录时生效）；三是安装一些第三方工具，类似于proxychain之类的。 但做了配置之后（不过我只试验了前2种），的确可以使用curl、wget等访问http资源了，但apt还是无法访问外部源，而且配置生效的范围相对局限。这又如何解决呢？ 突然想到安装了gui的ubuntu，可以在系统设置中配置全局代理，遂找了个有gui的虚机试验了一把，果然发现配置生效后有两个文件发生了变化，打开具体看一眼，内容是这样滴123456# /etc/environmenthttp_proxy=&quot;http://192.168.128.129:3128/&quot;https_proxy=&quot;https://192.168.128.129:3128/&quot;ftp_proxy=&quot;ftp://192.168.128.129:3128/&quot;socks_proxy=&quot;socks://192.168.128.129:3128/&quot; 123456# /etc/apt/apt.confAcquire::http::proxy &quot;http://192.168.128.129:3128/&quot;;Acquire::https::proxy &quot;https://192.168.128.129:3128/&quot;;Acquire::ftp::proxy &quot;ftp://192.168.128.129:3128/&quot;;Acquire::socks::proxy &quot;socks://192.168.128.129:3128/&quot;; 这么看来，前者配置的是系统全局代理服务器，后者则是针对apt做了单独的配置，这篇文章也应征了这个说法（ubuntu 10.10以后apt代理从后一个文件中读取）。 好了，将这两个文件新增的内容拷贝出来，贴到需要配置全局代理的内网主机的相同文件中去吧！ 2017-01-14补充除了apt，发现mvn也不走系统全局代理（捂脸）…… maven的代理配置位于setting.xml文件中的节，看着修改下host和port就可以了，说起来也蛮简单的。","categories":[{"name":"Linux","slug":"linux","permalink":"http://www.lx1992.com.cn/categories/linux/"}],"tags":[]},{"title":"搭建MySQL服务器","slug":"install-mysql-server","date":"2017-01-01T09:15:58.000Z","updated":"2017-01-26T20:01:43.777Z","comments":true,"path":"2017/01/01/install-mysql-server/","link":"","permalink":"http://www.lx1992.com.cn/2017/01/01/install-mysql-server/","excerpt":"不论是即将开发的程序，还是开发过程中必不可少的git、wiki等工具，它们都需要用数据库来保存自身的数据，所以搭建服务器的第一步自然是先把mysql搭起来。","text":"不论是即将开发的程序，还是开发过程中必不可少的git、wiki等工具，它们都需要用数据库来保存自身的数据，所以搭建服务器的第一步自然是先把mysql搭起来。 1. 安装mysql-server第一步当然是要安装好mysql-server。虽然通过apt默认源亦可完成安装，但是看mysql官方说明推荐用他们的源，就照着办吧！ 12345678# 切到/tmp目录，下载官方apt源的配置文件并安装cd /tmpwget http://dev.mysql.com/get/mysql-apt-config_0.8.1-1_all.debdpkg -i mysql-apt-config_0.8.1-1_all.deb# 更新软件源，安装mysql-serverapt updateapt install mysql-server 配置源的时候会问你想安装哪些组件、什么版本，作为服务器，只需要安装mysql-server，而出于稳定性考虑，选择5.7的稳定版本；安装的过程中，会要求输入数据库root用户的密码，总共就这2步操作～ 2. 修改数据库端口和路径刚刚安装好的mysql-server有一些配置可能不完全适用于我们的环境，因此需要修改一下，主要是数据库端口和路径。修改配置之前需要先停止mysql服务，顺带着复习下服务的简单操作。12345678# 启动mysql服务service mysql start# 停止mysql服务service mysql stop# 查看mysql服务当前状态service mysql status 2.1 配置文件在哪网上说，mysql默认从这4个地方寻找配置文件，以先找到的为准，而ubuntu系统中，配置文件默认是下面的第2个1234/etc/my.cnf/etc/mysql/my.cnf/usr/etc/my.cnf~/.my.cnf 但是有点奇怪，打开这第2个文件，里面只有一行1!includedir /etc/mysql/conf.d/ 字面上的意思应该是加载/etc/mysql/conf.d/下的文件，再打开这个目录，只有一个配置组是[mysql]的空的配置文件。 进一步看了下，真正的配置文件应该是/etc/mysql/mysql.cnf，因为它进一步加载了/etc/mysql/mysql.conf.d/mysqld.cnf文件，而我们要修改的[mysqld]配置组正位于其中。这个问题还待熟悉mysql配置的同学解释下哈。 2.2 修改数据库端口mysql默认监听3306端口，这是大多数人都知道的。但是呢，出于安全考虑，线上服务基本上不会保持默认端口，甚至都不会开启这附近的端口区间。要修改这个默认监听的端口，只需要修改（添加）port配置项等号后面的数字12port = 10086bind-address = 0.0.0.0 顺带着地，把bind-address配置项也修改一下，它的默认值是localhost，也就意味着只能从本机连接到mysql服务，这不符合我们的需求，将它改成上面的0.0.0.0即放开这个限制。 2.3 修改数据库路径mysql默认将数据库及自身的许多重要文件放置在/var/lib/mysql这个目录下，对大多数云主机来说，这个目录就位于系统盘中，这样即不方便也不安全，再者我们的云主机都购买了数据盘呢，显然应该将这个目录移出来。 如果不放心到底是不是这个目录，可以登录mysql命令行，运行一下1show variables like &apos;%dir%&apos;; 其中data_dir变量的值就是当前数据库的路径。 接着即可修改配置文件中的data_dir配置项了12datadir = /data/mysqllog-error = /data/logs/mysql/error.log 顺带着的，可以将log的路径也修改一下。修改完路径别忘了把已有的文件复制过去，复制的时候千万留意权限的变化。 3. 踩坑时间敲！黑！板！以为这样就万事大吉，可以重启服务了？嗯，重启是没报错，可是配置也没有生效啊…… 3.1 那啥AppArmor实话说，我也不知道这是啥，资料显示是ubuntu的一种沙箱机制吧，反正2.3节修改数据库路径的时候，少了这一步可不行（惯性思维了，以前Windows上没这一步），而且就是它导致了没报错、配置却不生效。 一开始我看了这篇文章，相应地修改了/etc/apparmor.d/usr.sbin.mysqld和/etc/apparmor.d/abstractions/mysql两个文件。 结果好了，启动报错还没有任何日志输出，谷歌一下大部分结果出错的还都是mysqld.service而不是我遇到的mysql.service1Job for mysql.service failed. See &apos;systemctl status mysqld.service&apos; and &apos;journalctl -xn&apos; for details. 幸运的是后来又找到了另一篇文章。这篇文章提到了另一种思路，为数据库路径起个别名，而不是直接改掉路径。 需要修改的文件变成了/etc/apparmor.d/tunables/alias，打开这个文件，赫然发现这么一行12# Or if mysql databases are stored in /home:alias /var/lib/mysql/ -&gt; /data/mysql/, 真的是柳暗花明啊，改之，然后别忘了先重启apparmor服务，后重启mysql服务/。瞄一眼新的数据库路径，文件的修改时间变了，日志也写进来了，Oh yeah~ 3.2 登录不了了改完了总得测试下吧？1mysql -uroot -p 曾经的mysql&gt;提示符没看到，看到的是1ERROR 1698 (28000): Access denied for user &apos;root&apos;@&apos;localhost&apos;. 密码肯定没错，如果本地都不能以root登录，那未必……，更奇怪的是，加上sudo就可以登录，看来是权限又给我桶啥篓子了（所以我说前面复制文件的时候注意权限），可检查了一番似乎又没啥问题 继续谷歌吧，解决方案这回倒不难找，可人家多是安装了mariadb导致的，我并没有哇！ 反正最终的解决方案就是重新建了个root用户，刚好我这边会有多个应用共用一个数据库，为了控制好权限，每个应用有自己的数据库用户名和密码，就当是复习下mysql用户操作了。1234567891011121314# 删除用户rootdrop user &apos;root&apos;@&apos;localhost&apos;;# 创建用户root 只允许从localhost登录 密码123456create user &apos;root&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;# 修改root用户密码(直接重置密码后会要求执行以下命令)alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;# 赋予用户root全部权限 允许转授权grant all privileges on *.* to &apos;root&apos;@&apos;localhost&apos; with grant option;# 权限立即生效flush privileges; 内容就是这些了，如果有同学能帮我解释踩下的几个坑，欢迎留言。","categories":[{"name":"MySQL","slug":"mysql","permalink":"http://www.lx1992.com.cn/categories/mysql/"}],"tags":[]},{"title":"用iptables实现端口映射","slug":"port-mapping-by-iptables","date":"2016-12-30T14:43:23.000Z","updated":"2017-01-26T19:41:15.431Z","comments":true,"path":"2016/12/30/port-mapping-by-iptables/","link":"","permalink":"http://www.lx1992.com.cn/2016/12/30/port-mapping-by-iptables/","excerpt":"按照项目对云主机的规划，只有一台主机具有外网IP（下文称A主机），其他主机都只有内网IP（下文称B主机）。换句话说，只有A主机可以访问外网，B主机不行。虽然这是出于安全性和成本等方面的考虑（数据库、后端接口等不宜暴露），但是这样一来，管理B主机都很成问题了，如何解决呢？","text":"按照项目对云主机的规划，只有一台主机具有外网IP（下文称A主机），其他主机都只有内网IP（下文称B主机）。换句话说，只有A主机可以访问外网，B主机不行。虽然这是出于安全性和成本等方面的考虑（数据库、后端接口等不宜暴露），但是这样一来，管理B主机都很成问题了，如何解决呢？ 索性所有云主机将会位于同一个机房，内网是互通的，因此可以在A主机上，用Linux系统的神器iptables配置端口转发，从而实现从外网对B主机的访问。下面的配置都在A主机上完成。 已知A机器内网IP：192.168.1.68，外网IP：10.0.0.9，B机器内网IP：192.168.1.64，要实现设置当外网访问A机器22681端口时转发至B机器22端口，也即可以使用命令直接从外网登录B主机1ssh -p 22681 username(B)@hostname(A) 首先要启用IPv4转发，打开/etc/sysctl.conf文件，将这一行前的注释符号去掉1net.ipv4.ip_forward=0 保存后不放心的话可以用这个命令检查一下（p=print）1sysctl -p 然后是配置转发，步骤如下： 1234#设置将A机器内网22681端口上的请求转发至B机器上iptables -t nat -A PREROUTING -d 192.168.1.68 -p tcp –dport 22681 -j DNAT –to-destination 192.168.1.64:22#将B机器的应答数据返回至A机器iptables -t nat -A POSTROUTING -s 0.0.0.0/0 -p tcp –dport 22 -j SNAT –to-source 192.168.1.68 最后是保存配置1iptables-save 当然，Linux系统中iptables其实是个很复杂的东西，要不然怎么可以称之为“神器”嘛，前面配置的时候一大堆PREROUTING、POSTROUTING、DNAT、SNAT的本文也没有多做解释，有想要详细了解的，我觉着这篇文章分析的还算详细。","categories":[{"name":"Linux","slug":"linux","permalink":"http://www.lx1992.com.cn/categories/linux/"}],"tags":[]},{"title":"Ubuntu设置静态IP地址","slug":"set-static-ip-in-ubuntu","date":"2016-12-25T02:36:30.000Z","updated":"2017-01-26T19:34:37.891Z","comments":true,"path":"2016/12/25/set-static-ip-in-ubuntu/","link":"","permalink":"http://www.lx1992.com.cn/2016/12/25/set-static-ip-in-ubuntu/","excerpt":"半年的实习就要结束咯～要回来干活咯～把荒废已久的博客捡起来先～ 老板给了个「小」项目，还没买云主机，先在线下用几台VMWare虚机搭建了一个相似的开发环境，然后就发现了个问题——几台虚机都由DHCP分配IP地址，重启时可能会改变，这样就会影响虚机间的通信，因此要给它们设置静态IP地址。","text":"半年的实习就要结束咯～要回来干活咯～把荒废已久的博客捡起来先～ 老板给了个「小」项目，还没买云主机，先在线下用几台VMWare虚机搭建了一个相似的开发环境，然后就发现了个问题——几台虚机都由DHCP分配IP地址，重启时可能会改变，这样就会影响虚机间的通信，因此要给它们设置静态IP地址。 首先要关闭VMWare的DHCP服务。打开VMWare网络编辑器，因为虚机采用了NAT方式联网，因此找到vmnet8下的use local DHCP service to distribute IP addresses to VMs选项，将其关闭。 记得打开NAT Settings界面看下vmnet8的网关，后面的配置中要用到，例如我这里是192.168.207.2。 接着就可以修改虚机网卡的IP地址了。vim打开/etc/network/interface文件，可以看到下面的内容 1234567# The loopback network interfaceauto loiface lo inet loopback# The primary network interfaceauto ens33iface ens33 inet dhcp 其中的lo是本地回环，而ens33才是虚机的网卡。修改这个文件：将dhcp改成static，然后加上address、netmask、gateway三个字段，分别用于配置IP地址、子网掩码和网关，配置后类似于这样 12345678910# The loopback network interfaceauto loiface lo inet loopback# The primary network interfaceauto ens33iface ens33 inet staticaddress 192.168.207.128netmask 255.255.255.0gateway 192.168.207.2 最后还要修改DNS配置。网上的很多说法是修改/etc/resolv.conf文件，但是打开这个文件就会看到大大的一行 DO NOT EDIT THIS FILE BY HAND – YOUR CHANGES WILL BE OVERWRITTEN 哎，人家都让你别改了！ 正确的做法应该是修改/etc/resolvconf/resolv.conf.d下的文件。网上的说法是这个目录下有head、tail、base三个文件，但我这只有head和base两个，而且head文件同样标记了不要修改，base是一个空文件。 将base改成下面这样（也就是加上一个或多个nameserver字段，图省事，直接拿了个114的dns）1nameserver 114.114.114.114 最后别忘了1/etc/inid.d/networking restart 重启下网络。OK，大功告成！","categories":[{"name":"Linux","slug":"linux","permalink":"http://www.lx1992.com.cn/categories/linux/"}],"tags":[]}]}